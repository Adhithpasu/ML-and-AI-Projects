{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using regular logistic Regression (Highest Accuracy estimate(so far): 83%"
      ],
      "metadata": {
        "id": "MzqDlYenTCb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VycaGV_zrYz7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "d = pd.read_csv(\"student_lifestyle_dataset.csv\")\n",
        "Y = d[\"Stress_Level\"]\n",
        "dic = {\"Moderate\": 1, \"High\": 2, \"Low\": 0}\n",
        "for i, element in np.ndenumerate(Y):\n",
        "  Y[i,] = dic[element]\n",
        "X = d.drop(\"Stress_Level\", axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, train_size=0.8)\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
        "w = [np.zeros(x_train.shape[1]) for i in range(3)]\n",
        "b = np.array([0.0 for i in range(3)])\n",
        "\n",
        "def softmax(z):\n",
        "  e_z = np.exp(z - np.max(z))\n",
        "  return e_z/sum(e_z)\n",
        "\n",
        "def forwardPass(weights, x, biases):\n",
        "  z = np.array([np.dot(w, x) + b for w, b in zip(weights, biases)])\n",
        "  a = softmax(z)\n",
        "  return z, a\n",
        "\n",
        "def cross_entropy(y, y_pred):\n",
        "  return -np.sum(y * np.log(y_pred + 1e-4))\n",
        "\n",
        "def backprop(x, y, a):\n",
        "  dz = a-y\n",
        "  dw = [dz[i] * x for i in range(len(dz))]\n",
        "  db = dz\n",
        "  return dw, db\n",
        "\n",
        "epochs = 2000\n",
        "alpha = 0.01\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for x, y in zip(x_train, y_train_one_hot):\n",
        "    z, a = forwardPass(w, x, b)\n",
        "    loss = cross_entropy(y, a)\n",
        "    total_loss += loss\n",
        "    dw, db = backprop(x, y, a)\n",
        "    for i in range(3):\n",
        "      w[i] -= alpha * dw[i]\n",
        "      b[i] -= alpha * db[i]\n",
        "  print(\"Loss at Epoch\" + str(epoch +1)+ \": \" + str(total_loss/len(x_train)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, w, b):\n",
        "  _, a = forwardPass(w, x, b)\n",
        "  return np.argmax(a)\n",
        "\n",
        "predictions = [predict(x, w, b) for x in x_test]\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_test = np.array(y_test).astype(np.int64)\n",
        "predictions = np.array(predictions).astype(np.int64)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy on test set:\", accuracy)"
      ],
      "metadata": {
        "id": "90O27eYWOBeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Neural Network Model Highest Accuracy estimate (so far): 98%-97%"
      ],
      "metadata": {
        "id": "zbK7PhT-TZXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "d = pd.read_csv(\"student_lifestyle_dataset.csv\")\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "Y = d[\"Stress_Level\"]\n",
        "X = d.drop(\"Stress_Level\", axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "dic = {\"Moderate\": 1, \"High\": 2, \"Low\": 0}\n",
        "print(Y.shape)\n",
        "for i, element in np.ndenumerate(Y):\n",
        "  Y[i,] = dic[element]\n",
        "print(Y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, train_size=0.8)\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test = y_test.astype(np.int64)\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(activation=\"relu\", units=125, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "        layers.Dense(activation=\"relu\", units=75, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "        layers.Dense(activation=\"relu\", units=15, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "        layers.Dense(activation=\"softmax\", units=3)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=200\n",
        ")\n"
      ],
      "metadata": {
        "id": "A1mAPsTfO-v3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}