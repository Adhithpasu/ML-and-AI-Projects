{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHOtS1xGmcX_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn # This will make the weights and baises tensors to be apart of the NN\n",
        "import torch.nn.functional as F # This gives us the activation functions\n",
        "from torch.optim import SGD # S|GD (Stochastic Gradient Descent) this will be used to fit our NN to the data\n",
        "import matplotlib.pyplot as plt # matplotlib and seaborn are used to plot graphs\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Required\n",
        "# In order to create a NN you start with a class\n",
        "class BasicNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() # This call the initalizatino funciton in the nn.Module\n",
        "    # You are initalizing your weights and baises here and setting values to them\n",
        "    self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False) # The requires_grad is set to false because we do not want to optimize this\n",
        "    self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
        "    self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
        "\n",
        "    self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
        "    self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
        "    self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
        "    self.final_bais = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n",
        "  # This is for foward pass\n",
        "  def forward(self, input):\n",
        "    Z_value_Top_Relu = input * self.w00 + self.b00\n",
        "    top_relu_func = F.relu(Z_value_Top_Relu)\n",
        "    Scaled_Z_value_Top_Relu = top_relu_func * self.w01\n",
        "\n",
        "    Z_value_bottom_Relu = input * self.w10 + self.b10\n",
        "    bottom_relu_func = F.relu(Z_value_bottom_Relu)\n",
        "    Scaled_Z_value_Bottom_Relu = bottom_relu_func * self.w11\n",
        "\n",
        "    input_to_final_relu = Scaled_Z_value_Bottom_Relu + Scaled_Z_value_Top_Relu + self.final_bais\n",
        "    output = F.relu(input_to_final_relu)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "Bir2hwTSmiVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_doses = torch.linspace(start=0, end=1, steps=11)\n",
        "input_doses"
      ],
      "metadata": {
        "id": "ZBHibyGy_LNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicNN()\n",
        "output_vals = model.forward(input_doses)"
      ],
      "metadata": {
        "id": "OVYs2ZfQ_V-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "sns.lineplot(x=input_doses, y=output_vals, color=\"green\", linewidth=2.5)\n",
        "plt.ylabel(\"Effectiveness\")\n",
        "plt.xlabel(\"Dose\")"
      ],
      "metadata": {
        "id": "44fa9EeV_uOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Basic_NN_train(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
        "    self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
        "    self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
        "\n",
        "    self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
        "    self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
        "    self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
        "    self.final_bias = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "  def forward(self, input):\n",
        "    z_top_relu = input * self.w00 + self.b00\n",
        "    z_bottom_relu= input * self.w10 + self.b10\n",
        "    relu_value_top = F.relu(z_top_relu)\n",
        "    relu_value_bottom = F.relu(z_bottom_relu)\n",
        "    Scaled_top_val = relu_value_top * self.w01\n",
        "    Scaled_bottom_val = relu_value_bottom * self.w11\n",
        "    final_z = Scaled_bottom_val + Scaled_top_val + self.final_bias\n",
        "    return F.relu(final_z)\n"
      ],
      "metadata": {
        "id": "xxbpTP6sBOwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Basic_NN_train()\n",
        "output_vals = model.forward(input_doses)"
      ],
      "metadata": {
        "id": "vrvxd07BDosg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "sns.lineplot(x=input_doses, y=output_vals.detach(), color=\"green\", linewidth=2.5)\n",
        "plt.ylabel(\"Effectiveness\")\n",
        "plt.xlabel(\"Dose\")\n"
      ],
      "metadata": {
        "id": "rzgoyLMND8F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([0., 0.5, 1.0])\n",
        "labels = torch.tensor([0.0, 1.0, 0.0])\n"
      ],
      "metadata": {
        "id": "gjAGzzUVEiad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.1) # We use the Stochastic Gradient Descent to optimze or weights and biases using a learning rate of 0.1\n",
        "print(\"Final Bias before training: \" + str(model.final_bias.data))"
      ],
      "metadata": {
        "id": "uy8Or_PzbRYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  total_loss = 0\n",
        "  for iter in range(len(inputs)):\n",
        "    pred = model.forward(inputs[iter])\n",
        "    squared_residuals = (labels[iter] - pred)**2\n",
        "    squared_residuals.backward() # This is used for backpropagation and the derivatives are added together (The reason for adding is in the link: https://www.google.com/search?q=why+does+.backward()+add+the+derivatives+in+pytorch&rlz=1C5CHFA_enUS979US980&oq=why+does+.backward()+add+the+derivatives+in+pytorch&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRifBTIHCAIQIRifBTIHCAMQIRifBTIHCAQQIRifBTIHCAUQIRifBTIHCAYQIRifBTIHCAcQIRifBTIHCAgQIRifBTIHCAkQIRifBdIBCTEzOTMxajFqN6gCALACAA&sourceid=chrome&ie=UTF-8)\n",
        "    total_loss += float(squared_residuals)\n",
        "  if total_loss < 0.0001:\n",
        "    print(\"Num steps: \" + str(epoch))\n",
        "    break\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad() # This is used to clear the previous derivatives stored in .grad which contains the sum of the derivatives\n",
        "  print(\"Step: \" + str(epoch) + \" Final bias: \" + str(model.final_bias.data))\n",
        "\n",
        "print(\"Final Bias before training: \" + str(model.final_bias.data))"
      ],
      "metadata": {
        "id": "5MkRv1b6cGKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_vals = model.forward(input_doses)\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.lineplot(x=input_doses, y=output_vals.detach(), color=\"green\", linewidth=2.5)\n",
        "plt.ylabel(\"Effectiveness\")\n",
        "plt.xlabel(\"Dose\")\n"
      ],
      "metadata": {
        "id": "xK8_l4fGnw41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5XFq0ex9otZP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}